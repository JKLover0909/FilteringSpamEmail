{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cVAYA-lEhC6u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from typing import Tuple, List, Dict\n",
        "from tabulate import tabulate\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã ghi nội dung các tệp trong thư mục 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/TrainData/notspam'và 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/TrainData/spam vào 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/pythonspamemail/x.csv'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "df_list = []\n",
        "\n",
        "def read_files_and_write_to_csv(folder_path_1, folder_path_2, output_csv_path):    \n",
        "    # Mở tệp CSV để ghi\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['NoiDung', 'label'])\n",
        "        \n",
        "        # Lặp qua các tệp trong thư mục\n",
        "        for filename in os.listdir(folder_path_1):\n",
        "            file_path_1 = os.path.join(folder_path_1, filename)\n",
        "            \n",
        "            # Kiểm tra xem tệp có phải là tệp văn bản không\n",
        "            if os.path.isfile(file_path_1) and file_path_1.endswith('.txt'):\n",
        "                with open(file_path_1, 'r', encoding='utf-8') as txt_file_1:\n",
        "                    content = txt_file_1.read()\n",
        "                    csv_writer.writerow([content, \"notspam\"])\n",
        "                    \n",
        "        for filename in os.listdir(folder_path_2):\n",
        "            file_path_2 = os.path.join(folder_path_2, filename)\n",
        "            \n",
        "            # Kiểm tra xem tệp có phải là tệp văn bản không\n",
        "            if os.path.isfile(file_path_2) and file_path_2.endswith('.txt'):\n",
        "                with open(file_path_2, 'r', encoding='utf-8') as txt_file_2:\n",
        "                    content = txt_file_2.read()\n",
        "                    csv_writer.writerow([content, \"spam\"])            \n",
        "    \n",
        "    print(f\"Đã ghi nội dung các tệp trong thư mục '{folder_path_1}'và '{folder_path_2} vào '{output_csv_path}'.\")\n",
        "\n",
        "# Đường dẫn đến thư mục chứa các tệp\n",
        "folder_path_1 = 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/TrainData/notspam'\n",
        "folder_path_2 = 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/TrainData/spam'\n",
        "# Đường dẫn đến tệp CSV đích\n",
        "output_csv_path = 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/pythonspamemail/x.csv'\n",
        "\n",
        "read_files_and_write_to_csv(folder_path_1,folder_path_2, output_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_list = pd.read_csv('C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/pythonspamemail/x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "bB6hBpnIhC61",
        "outputId": "1551f727-b18e-459d-f3a7-28b0634afbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               NoiDung    label\n",
            "0    Subject: re : 2 . 882 s - > np np\\n\\n> date : ...  notspam\n",
            "1    Subject: job announcement\\n\\njob announcement ...  notspam\n",
            "2    Subject: translators needed women women !\\n\\na...  notspam\n",
            "3    Subject: contributions solicited germanic gene...  notspam\n",
            "4    Subject: celiac / oaxaca native literacy proje...  notspam\n",
            "..                                                 ...      ...\n",
            "206  Subject: lists software worldwide\\n\\norder for...     spam\n",
            "207  Subject: zero down internet opportunity !\\n\\n$...     spam\n",
            "208  Subject: re : free !\\n\\nhello , are offering f...     spam\n",
            "209  Subject: \\n\\ncomes porn , site does n't mess a...     spam\n",
            "210  Subject: even steal identity !\\n\\nare being in...     spam\n",
            "\n",
            "[211 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_list)\n",
        "\n",
        "df = df_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OjqsbHtqhC62"
      },
      "outputs": [],
      "source": [
        "def text_preprocess(mess):\n",
        "    nopunc = [char for char in mess if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "    nopunc = nopunc.lower()\n",
        "    nostop=[word for word in nopunc.split() if word.lower() not in stopwords.words('english') and word.isalpha()]\n",
        "\n",
        "    return nostop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7givQKsEvOOs"
      },
      "outputs": [],
      "source": [
        "spam_messages = df[df[\"label\"] == \"spam\"][\"NoiDung\"]\n",
        "notspam_messages = df[df[\"label\"] == \"notspam\"][\"NoiDung\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGfSrrm1uIlr",
        "outputId": "d16a2337-f271-4029-a86f-de1a70d79ee2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Words in spam messages\n",
        "spam_words = []\n",
        "for each_message in spam_messages:\n",
        "    spam_words += text_preprocess(each_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VVxvqtYvhC64"
      },
      "outputs": [],
      "source": [
        "df[\"NoiDung\"] = df[\"NoiDung\"].apply(text_preprocess)\n",
        "df[\"NoiDung\"] = df[\"NoiDung\"].agg(lambda x: \" \".join(map(str, x)))\n",
        "vectorizer = CountVectorizer()\n",
        "bow_transformer = vectorizer.fit(df[\"NoiDung\"])\n",
        "messages_bow = bow_transformer.transform(df[\"NoiDung\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MfkLGFVuvua",
        "outputId": "346483b0-decd-44db-bac9-f020512ca5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(211, 10343)\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
        "\n",
        "# Transform entire BoW into tf-idf corpus\n",
        "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
        "print(messages_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MQfxRS7qnTo0",
        "outputId": "2d30d66f-759f-4b6c-a33b-9a5da340cc8e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NoiDung</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject np np date sun dec est michael mmorse ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject job announcement job announcement depa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject translators needed women women posting...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject contributions solicited germanic gener...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject celiac oaxaca native literacy project ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>subject george aditjondro dr george aditjondro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>subject ua appeal arief budiman urgent action ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>subject designing dialects following appeared ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>subject language evolution context hello lingu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>subject quick note thank sent information conc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             NoiDung  label\n",
              "0  subject np np date sun dec est michael mmorse ...      0\n",
              "1  subject job announcement job announcement depa...      0\n",
              "2  subject translators needed women women posting...      0\n",
              "3  subject contributions solicited germanic gener...      0\n",
              "4  subject celiac oaxaca native literacy project ...      0\n",
              "5  subject george aditjondro dr george aditjondro...      0\n",
              "6  subject ua appeal arief budiman urgent action ...      0\n",
              "7  subject designing dialects following appeared ...      0\n",
              "8  subject language evolution context hello lingu...      0\n",
              "9  subject quick note thank sent information conc...      0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FactorResult = pd.factorize(df[\"label\"])\n",
        "df[\"label\"] = FactorResult[0]\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f_ETWkU3hC6-"
      },
      "outputs": [],
      "source": [
        "# Split the dataset to train and test sets\n",
        "msg_train, msg_test, label_train, label_test = train_test_split(\n",
        "    messages_tfidf, df[\"label\"], test_size=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "wWCoDIufhC6_",
        "outputId": "c1fef70f-8fc4-44ca-8426-0d7d57cf028b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train an xgboost classifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Instantiate our model\n",
        "clf = XGBClassifier()\n",
        "\n",
        "# Fit the model to the training data\n",
        "clf.fit(msg_train, label_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cNlsrTO6hC7A"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predict_train = clf.predict(msg_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nH8vw8w1hC7A"
      },
      "outputs": [],
      "source": [
        "no_labels = np.arange(0, 78)\n",
        "df_noLabel = []\n",
        "\n",
        "folder_path_3 = 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/TestData_nolabel/Testdata'\n",
        "\n",
        "output_csv_path_2 = 'C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/pythonspamemail/y.csv'\n",
        "\n",
        "with open(output_csv_path_2, 'w', newline='', encoding='utf-8') as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow(['NoiDung', 'label'])\n",
        "        \n",
        "        # Lặp qua các tệp trong thư mục\n",
        "        for filename in os.listdir(folder_path_3):\n",
        "            file_path_3 = os.path.join(folder_path_3, filename)\n",
        "            \n",
        "            # Kiểm tra xem tệp có phải là tệp văn bản không\n",
        "            if os.path.isfile(file_path_3) and file_path_3.endswith('.txt'):\n",
        "                with open(file_path_3, 'r', encoding='utf-8') as txt_file:\n",
        "                    content = txt_file.read()\n",
        "                    csv_writer.writerow([content])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J0GUdMrehC7A"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NoiDung</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: base generated adjuncts\\n\\ndoes anyon...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: 4th nottingham international systemic...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: salk insitute job\\n\\nresearch positio...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: speaks languages ?\\n\\n&gt; &gt; : vicki fro...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: syntax query\\n\\nmember tesl - l list ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Subject: syntax textbooks\\n\\nneed order textbo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Subject: re : 3 . 396 chomsky citations\\n\\nlin...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Subject: re : 3 . 396 chomsky citations\\n\\nlar...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Subject: chomsky citations\\n\\nalthough am fait...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Subject: re : 3 . 396 chomsky citations\\n\\nagr...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             NoiDung  label\n",
              "0  Subject: base generated adjuncts\\n\\ndoes anyon...    NaN\n",
              "1  Subject: 4th nottingham international systemic...    NaN\n",
              "2  Subject: salk insitute job\\n\\nresearch positio...    NaN\n",
              "3  Subject: speaks languages ?\\n\\n> > : vicki fro...    NaN\n",
              "4  Subject: syntax query\\n\\nmember tesl - l list ...    NaN\n",
              "5  Subject: syntax textbooks\\n\\nneed order textbo...    NaN\n",
              "6  Subject: re : 3 . 396 chomsky citations\\n\\nlin...    NaN\n",
              "7  Subject: re : 3 . 396 chomsky citations\\n\\nlar...    NaN\n",
              "8  Subject: chomsky citations\\n\\nalthough am fait...    NaN\n",
              "9  Subject: re : 3 . 396 chomsky citations\\n\\nagr...    NaN"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_noLabel1 = pd.read_csv('C:/Users/Admin/OneDrive - ptit.edu.vn/Documents/BLT_PYTHON/BTL_FilteringSpamEmail/pythonspamemail/y.csv')\n",
        "df_noLabel1.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qgmw7wXAhC7B"
      },
      "outputs": [],
      "source": [
        "df_noLabel1[\"NoiDung\"] = df_noLabel1[\"NoiDung\"].apply(text_preprocess)\n",
        "df_noLabel1[\"NoiDung\"] = df_noLabel1[\"NoiDung\"].agg(lambda x: \" \".join(map(str, x)))\n",
        "messages_bow_NL = bow_transformer.transform(df_noLabel1[\"NoiDung\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gdhRrf6ZwDDQ"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer().fit(messages_bow_NL)\n",
        "\n",
        "# Transform entire BoW into tf-idf corpus\n",
        "messages_tfidf_NL = tfidf_transformer.transform(messages_bow_NL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oowpHFCihC7C",
        "outputId": "d23059bd-3cae-4969-901c-7b45f958d19c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "model_pred = clf.predict(messages_tfidf_NL)\n",
        "model_pred = pd.DataFrame(model_pred)\n",
        "model_pred = model_pred.replace({0: 'nospam', 1: 'spam'})\n",
        "model_pred = model_pred.to_csv('ANSWER2.csv')\n",
        "print(model_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "736a84c09fc56c8724f350b643d4ce5f01d4f5cac1df10f2eab7d833431924e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
